{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook compare_metrics_over_datasets_v2.ipynb to python\n",
      "[NbConvertApp] Writing 8501 bytes to compare_metrics_over_datasets_v2.py\n"
     ]
    }
   ],
   "source": [
    "# noscript\n",
    "!jupyter nbconvert --RegexRemovePreprocessor.patterns=\"['# ?noscript']\" --TemplateExporter.exclude_markdown=True --to python compare_metrics_over_datasets_v2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import openml\n",
    "\n",
    "import sklearn.metrics\n",
    "import sklearn.ensemble\n",
    "import sklearn.svm\n",
    "import sklearn.preprocessing\n",
    "import sklearn.model_selection\n",
    "import sklearn.base\n",
    "import sklearn.utils\n",
    "import sklearn.linear_model\n",
    "import sklearn.naive_bayes\n",
    "import sklearn.neural_network\n",
    "import sklearn.tree\n",
    "\n",
    "from ridgereliability import plots, metrics\n",
    "\n",
    "import os\n",
    "import multiprocessing\n",
    "import logging\n",
    "import time\n",
    "from joblib import load, dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTAMP = int(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_ipython().__class__.__name__ != 'ZMQInteractiveShell':\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--n-processes\", type=int, required=True)\n",
    "    n_procs = parser.parse_args().n_processes\n",
    "else:\n",
    "    n_procs = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(asctime)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare metrics over datasets\n",
    "\n",
    "In this notebook we collect calibration estimates for several models and datasets. The estimates are computed with the Expected Calibration Error (ECE), Balanced-ECE, and Posterior Expected Accuracy-based Calibration Error (PEACE).\n",
    "\n",
    "Tested models:\n",
    "- Random Forest\n",
    "- SVM\n",
    "- Logistic Regression\n",
    "- Gaussian Naive Bayes\n",
    "- MLP\n",
    "- AdaBoost\n",
    "- Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "First of all, we need to be able to load and preprocess multiple datasets appropriately to prepare it for classification. \n",
    "To this end we implement a function that will load a dataset and classification task from OpenML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_random_tasks():\n",
    "    n_tasks = 100\n",
    "    \n",
    "    task_df = []\n",
    "    while len(task_df) < n_tasks:\n",
    "        n = n_tasks - len(task_df)\n",
    "        df = openml.tasks.list_tasks(task_type_id=1, output_format=\"dataframe\", size=10000, status=\"active\", number_missing_values=0).sample(n=n)\n",
    "        df = df[(df[\"NumberOfInstances\"] > 100) & (df[\"NumberOfInstances\"] < 1000)]\n",
    "        if type(task_df) is list:\n",
    "            task_df = df\n",
    "        else:\n",
    "            task_df = pandas.concat([task_df, df])\n",
    "        \n",
    "    return task_df[\"tid\"].values\n",
    "\n",
    "TASKS = find_random_tasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tasks_v2_1600961549.dat']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(TASKS, f\"tasks_v2_{int(time.time())}.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_openml_task(task_id):\n",
    "    task = openml.tasks.get_task(task_id)\n",
    "    X, y = task.get_X_and_y(\"dataframe\")\n",
    "    \n",
    "    X_enc = sklearn.preprocessing.OrdinalEncoder().fit_transform(X.values)\n",
    "    X = pandas.DataFrame(X_enc, columns=X.columns, index=X.index)\n",
    "    \n",
    "    n_repeats, n_folds, n_samples = task.get_split_dimensions()\n",
    "\n",
    "    folds = numpy.empty((len(X)), dtype=int)\n",
    "    for fold_idx in range(n_folds):\n",
    "        _, test_indices = task.get_train_test_split_indices(\n",
    "            repeat=0,\n",
    "            fold=fold_idx,\n",
    "            sample=0,\n",
    "        )\n",
    "        \n",
    "        folds[test_indices] = fold_idx\n",
    "        \n",
    "    splitter = sklearn.model_selection.PredefinedSplit(folds)\n",
    "                \n",
    "    return X, y, splitter        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: 2020-09-24 17:32:30,247 - Saved dataset 950: arsenic-female-lung to file /home/maximl/.openml/cache/org/openml/www/datasets/950/dataset.pkl.py3\n",
      "DEBUG: 2020-09-24 17:32:30,753 - Data pickle file already exists and is up to date.\n"
     ]
    }
   ],
   "source": [
    "# noscript\n",
    "X, y, splitter = load_openml_task(TASKS[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56,)\n",
      "(56,)\n",
      "(56,)\n",
      "(56,)\n",
      "(56,)\n",
      "(56,)\n",
      "(56,)\n",
      "(56,)\n",
      "(56,)\n",
      "(55,)\n"
     ]
    }
   ],
   "source": [
    "# noscript\n",
    "for train_idx, test_idx in splitter.split():\n",
    "    print(test_idx.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting calibration metrics\n",
    "\n",
    "For each dataset we fit and evaluate multiple models. We record calibration metrics (ECE, ECE-balanced, PEACE), and some performance metrics (balanced accuracy, F1-score, accuracy). To this end we implement a function that runs this procedure for one model on one OpenML task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = {\n",
    "    \"rf\": sklearn.ensemble.RandomForestClassifier(),\n",
    "    \"svm\": sklearn.svm.SVC(probability=True),\n",
    "    \"logreg\": sklearn.linear_model.LogisticRegression(max_iter=500),\n",
    "    \"nb\": sklearn.naive_bayes.GaussianNB(),\n",
    "    \"mlp\": sklearn.neural_network.MLPClassifier(max_iter=500),\n",
    "    \"adaboost\": sklearn.ensemble.AdaBoostClassifier(n_estimators=500),\n",
    "    \"dectree\": sklearn.tree.DecisionTreeClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fold_metrics_for_model(row, Xt, yt, Xv, yv):\n",
    "    # get and fit fresh model\n",
    "    model = sklearn.base.clone(MODELS[row[\"model_id\"]])\n",
    "    model.fit(Xt, yt)\n",
    "\n",
    "    # compute metrics on test data\n",
    "    y_probs = model.predict_proba(Xv)\n",
    "    y_probs_max = y_probs.max(axis=1)\n",
    "    y_preds = model.predict(Xv)\n",
    "    y_test = yv\n",
    "\n",
    "    bins = 15\n",
    "    row.update({\n",
    "        \"accuracy\": sklearn.metrics.accuracy_score(y_test, y_preds),\n",
    "        \"balanced_accuracy\": sklearn.metrics.balanced_accuracy_score(y_test, y_preds),\n",
    "        \"f1\": sklearn.metrics.f1_score(y_test, y_preds, average=\"weighted\"),\n",
    "        'ece': metrics.ece(y_probs_max, y_preds, y_test, bins=bins),\n",
    "        'ece_balanced': metrics.ece(y_probs_max, y_preds, y_test, balanced=True, bins=bins),\n",
    "        'peace': metrics.peace(y_probs_max, y_preds, y_test, bins=bins),\n",
    "        'class_wise_ece': metrics.class_wise_error(y_probs, y_preds, y_test, metrics.ece, bins=bins),\n",
    "        'class_wise_peace': metrics.class_wise_error(y_probs, y_preds, y_test, metrics.peace, bins=bins)\n",
    "    })\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cv_metrics_for_model_and_task(model_id, task_id, pool, n_repeats, counter, start_at):\n",
    "    \n",
    "    X, y, splitter = load_openml_task(task_id) # repeated runs will use cached data\n",
    "    \n",
    "    promises = []\n",
    "    for i, (train_idx, test_idx) in enumerate(splitter.split()):\n",
    "        for j in range(n_repeats):\n",
    "            counter += 1\n",
    "            if counter < start_at:\n",
    "                continue\n",
    "            \n",
    "            row = {\n",
    "                \"fold\": i,\n",
    "                \"repeat\": j,\n",
    "                \"model_id\": model_id,\n",
    "                \"task_id\": task_id,\n",
    "            }\n",
    "\n",
    "            # split data\n",
    "            Xt, yt = X.iloc[train_idx], y.iloc[train_idx]\n",
    "            Xv, yv = X.iloc[test_idx], y.iloc[test_idx]\n",
    "\n",
    "            promise = pool.apply_async(\n",
    "                get_fold_metrics_for_model,\n",
    "                (row, Xt, yt, Xv, yv)\n",
    "            )\n",
    "            promises.append(promise)\n",
    "        \n",
    "    return promises, counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data collection over all datasets and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: 2020-09-24 17:32:30,833 - Output to metrics_v2_1600961550.dat\n",
      "DEBUG: 2020-09-24 17:32:30,838 - Data pickle file already exists and is up to date.\n",
      "DEBUG: 2020-09-24 17:32:30,843 - Data pickle file already exists and is up to date.\n",
      "/home/maximl/.conda/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1814: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "/home/maximl/.conda/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1814: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "DEBUG: 2020-09-24 17:32:35,989 - Saved dataset 1155: AP_Prostate_Lung to file /home/maximl/.openml/cache/org/openml/www/datasets/1155/dataset.pkl.py3\n",
      "DEBUG: 2020-09-24 17:32:36,699 - Data pickle file already exists and is up to date.\n",
      "INFO: 2020-09-24 17:32:36,709 - Going to remove the following attributes: ['ID_REF']\n",
      "/home/maximl/.conda/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1814: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "/home/maximl/.conda/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1814: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "DEBUG: 2020-09-24 17:32:38,611 - Saved dataset 1553: autoUniv-au7-700 to file /home/maximl/.openml/cache/org/openml/www/datasets/1553/dataset.pkl.py3\n",
      "/home/maximl/.conda/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1814: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "DEBUG: 2020-09-24 17:32:38,853 - Data pickle file already exists and is up to date.\n",
      "/home/maximl/.conda/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1814: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "/home/maximl/.conda/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1814: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "/home/maximl/.conda/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1814: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "/home/maximl/.conda/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1814: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "/home/maximl/.conda/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1814: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "/home/maximl/.conda/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1814: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "/home/maximl/.conda/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1814: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "/home/maximl/.conda/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1814: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "/home/maximl/.conda/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1814: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "/home/maximl/.conda/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1814: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "DEBUG: 2020-09-24 17:32:39,858 - Saved dataset 954: spectrometer to file /home/maximl/.openml/cache/org/openml/www/datasets/954/dataset.pkl.py3\n",
      "DEBUG: 2020-09-24 17:32:40,087 - Data pickle file already exists and is up to date.\n",
      "INFO: 2020-09-24 17:32:40,088 - Going to remove the following attributes: ['LRS-name']\n",
      "/home/maximl/.conda/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1814: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "/home/maximl/.conda/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1814: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "/home/maximl/.conda/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1814: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "/home/maximl/.conda/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1814: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "/home/maximl/.conda/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1814: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "/home/maximl/.conda/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1814: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "/home/maximl/.conda/envs/ml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1814: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "Process ForkPoolWorker-9:\n",
      "Process ForkPoolWorker-6:\n",
      "Process ForkPoolWorker-2:\n",
      "Process ForkPoolWorker-1:\n",
      "Process ForkPoolWorker-4:\n",
      "Process ForkPoolWorker-8:\n",
      "Process ForkPoolWorker-12:\n",
      "Process ForkPoolWorker-11:\n",
      "Process ForkPoolWorker-7:\n",
      "Process ForkPoolWorker-3:\n",
      "Process ForkPoolWorker-5:\n",
      "Process ForkPoolWorker-10:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/queues.py\", line 356, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/maximl/.conda/envs/ml/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "with multiprocessing.Pool(processes=n_procs) as pool:\n",
    "    \n",
    "    start_at = 0\n",
    "    \n",
    "    output_file = f\"metrics_v2_{int(time.time())}.dat\"\n",
    "    logging.info(f\"Output to {output_file}\")\n",
    "    \n",
    "    promises = []\n",
    "    counter = 0\n",
    "    for model_id in MODELS.keys():\n",
    "        for task_id in TASKS:\n",
    "            tmp, counter = get_cv_metrics_for_model_and_task(model_id, task_id, pool, 1, counter, start_at)\n",
    "            promises.extend(tmp)\n",
    "            \n",
    "    logging.info(f\"{len(promises)} promises submitted to pool\")\n",
    "            \n",
    "    data = []\n",
    "    for promise in promises:\n",
    "        data.append(promise.get())\n",
    "        logging.info(f\"Finished promises: {len(data)}/{len(promises)} ({len(data)/len(promises)*100:.2f}%)\")\n",
    "        df = pandas.DataFrame(data)\n",
    "        dump(df, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_ipython().__class__.__name__ != 'ZMQInteractiveShell':\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load(\"/home/maximl/Data/Experiment_data/results/riverrel/metrics_1600940535.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load(\"metrics_1600957213.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = df.groupby([\"model_id\", \"task_id\", \"repeat\"]).aggregate(\"mean\").drop(columns=[\"fold\"]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_longform(df, cols=None, subject_cols=None):\n",
    "    dfs = []\n",
    "    \n",
    "    if cols is None:\n",
    "        cols = df.columns\n",
    "    \n",
    "    for col in cols:\n",
    "        tmp_df = pandas.DataFrame(dict(        \n",
    "            value=df[col], \n",
    "            metric=col,   \n",
    "        ))\n",
    "        for col2 in set(df.columns) - set(cols):\n",
    "            tmp_df[col2] = df[col2]\n",
    "            \n",
    "        if subject_cols is not None:\n",
    "            tmp_df[\"subject\"] = df[subject_cols].apply(lambda row: '_'.join(row.values.astype(str)), axis=1)\n",
    "            \n",
    "        dfs.append(tmp_df)\n",
    "        \n",
    "    return pandas.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df = get_longform(grouped_df, grouped_df.columns[3:], [\"model_id\", \"task_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.catplot(data=long_df[long_df[\"metric\"].isin([\"accuracy\", \"balanced_accuracy\", \"f1\"])], x=\"model_id\", y=\"value\", col=\"metric\", kind=\"box\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.catplot(data=long_df[long_df[\"metric\"].isin([\"accuracy\", \"balanced_accuracy\", \"f1\"])], x=\"task_id\", y=\"value\", col=\"metric\", kind=\"box\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.displot(data=long_df[long_df[\"metric\"].isin([\"ece\", \"ece_balanced\", \"peace\"])], x=\"value\", col=\"metric\", rug=True, kind=\"kde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.boxplot(data=long_df[long_df[\"metric\"].isin([\"ece\", \"ece_balanced\", \"peace\"])], y=\"value\", x=\"metric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.lineplot(data=long_df[long_df[\"metric\"].isin([\"ece\", \"ece_balanced\", \"peace\"])], y=\"value\", x=\"metric\", hue=\"subject\", err_style=\"bars\", palette=\"tab10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "import scikit_posthocs as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooled datasets + model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = grouped_df.loc[grouped_df[\"repeat\"] == 0, [\"ece\", \"ece_balanced\", \"peace\"]].values\n",
    "scipy.stats.friedmanchisquare(data[0], data[1], data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_data = get_longform(grouped_df.loc[grouped_df[\"repeat\"] == 0, [\"ece\", \"ece_balanced\", \"peace\"]])\n",
    "sp.posthoc_conover(long_data, val_col=\"value\", group_col=\"metric\", p_adjust=\"holm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, model_df in grouped_df.groupby(\"model_id\"):\n",
    "    data = model_df.loc[:, [\"ece\", \"ece_balanced\", \"peace\"]]\n",
    "    test = scipy.stats.friedmanchisquare(data.iloc[:, 0], data.iloc[:, 1], data.iloc[:, 2])\n",
    "    print(idx)\n",
    "    print(test)\n",
    "    if test.pvalue < 0.05:\n",
    "        long_data = get_longform(data)\n",
    "        print(sp.posthoc_conover(long_data, val_col=\"value\", group_col=\"metric\", p_adjust=\"holm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.catplot(data=long_df[long_df[\"metric\"].isin([\"ece\", \"ece_balanced\", \"peace\"])], x=\"metric\", y=\"value\", col=\"model_id\", kind=\"box\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
