# AUTOGENERATED! DO NOT EDIT! File to edit: notebooks/metrics.ipynb (unless otherwise specified).

__all__ = ['ece', 'ece_v2', 'peace', 'class_wise_ece']

# Cell

from ridgereliability import utils

import numpy as np
import scipy.stats
import scipy.integrate

import ridgereliability.beta
import sklearn.metrics

# Cell

def ece(y_probs, y_preds, y_true, balanced=False, bins="fd"):
    """Compute the expected calibration error (ECE).

    Parameters:
    y_probs (np.array): predicted class probabilities
    y_preds (np.array): predicted class labels
    y_true (np.array): true class labels

    Returns:
    exp_ce (float): expected calibration error

    """

    # define the bin function
    def bin_func(y_probs_bin, y_preds_bin, y_true_bin):
        acc = (y_preds_bin == y_true_bin).mean()
        conf = y_probs_bin.mean()
        return abs(acc - conf)

    # define the balanced bin function
    def balanced_bin_func(y_probs_bin, y_preds_bin, y_true_bin):
        balacc = sklearn.metrics.balanced_accuracy_score(y_true_bin, y_preds_bin)
        conf = y_probs_bin.mean()
        return abs(balacc - conf)

    # compute the full result
    bin_indices = utils.get_bin_indices(y_probs, bins=bins)
    func = balanced_bin_func if balanced else bin_func
    return utils.binning(y_probs, y_preds, y_true, bin_indices, func)

# Cell

def ece_v2(y_probs, y_preds, y_true, bins="fd"):
    """Compute the expected calibration error based on the expected posterior balanced accuracy (ECEv2).

    Parameters:
    y_probs (np.array): predicted class probabilities
    y_preds (np.array): predicted class labels
    y_true (np.array): true class labels

    Returns:
    exp_ce (float): expected calibration error

    """

    # define the bin function
    def bin_func(y_probs_bin, y_preds_bin, y_true_bin):
        confusion = sklearn.metrics.confusion_matrix(y_true_bin, y_preds_bin)
        acc = ridgereliability.beta.balanced_accuracy_expected(confusion, fft=True)
        conf = y_probs_bin.mean()
        return abs(acc - conf)

    # compute the full result
    bin_indices = utils.get_bin_indices(y_probs, bins=bins)
    return utils.binning(y_probs, y_preds, y_true, bin_indices, bin_func)

# Cell

def peace(y_probs, y_preds, y_true, samples=1000, bins="fd"):
    """Compute the posterior expected balanced accuracy-based calibration error (PEACE).

    Parameters:
    y_probs (np.array): predicted class probabilities
    y_preds (np.array): predicted class labels
    y_true (np.array): true class labels
    samples (int): number of samples for numerical integration

    Returns:
    exp_ce (float): expected calibration error

    """

    # define the bin function
    def bin_func(y_probs_bin, y_preds_bin, y_true_bin):
        # estimate beta parameters
        confusion = sklearn.metrics.confusion_matrix(y_true_bin, y_preds_bin)
        params = ridgereliability.beta.get_beta_parameters(confusion)

        # approximate the integral using Simpson's rule
        xs = np.linspace(0, 1, samples)
        conf = y_probs_bin.mean()
        ys = abs(xs - conf) * ridgereliability.beta.beta_avg_pdf(xs, params, fft=True)
        return scipy.integrate.simps(ys, xs)

    # compute the full result
    bin_indices = utils.get_bin_indices(y_probs, bins=bins)
    return utils.binning(y_probs, y_preds, y_true, bin_indices, bin_func)

# Cell

def class_wise_ece(y_probs, y_preds, y_true, base_ece, *base_ece_args, **base_ece_kwargs):
    """Compute classwise-ECE as proposed in "Beyond temperature scaling: Obtaining well-calibrated
    multiclass probabilities with Dirichlet calibration" (Kull, 2019).

    Parameters:
    y_probs (np.array): predicted class probabilities
    y_preds (np.array): predicted class labels
    y_true (np.array): true class labels
    base_ece (callable): function that returns ECE for given probabilities, label predictions and true labels
    base_ece_[kw]args ([kw]args): [Keyword ]arguments that should be passed to the base_ece callable.

    Returns:
    exp_ce (float): class-wise expected calibration error

    """

    classes = np.unique(y_preds)
    result = 0.
    for j in classes:
        sel = y_preds == j
        result += base_ece(y_probs[sel], y_preds[sel], y_true[sel], *base_ece_args, **base_ece_kwargs)

    return result/len(classes)