{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beta distribution utilities\n",
    "\n",
    "Utility functions for working with beta distributions. Adapted from the [`mclearn`](https://github.com/chengsoonong/mclass-sky) package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import beta\n",
    "from scipy.integrate import trapz\n",
    "from scipy.optimize import brentq\n",
    "from sklearn import metrics\n",
    "import numpy.fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def get_beta_parameters(confusion):\n",
    "    \"\"\" Extract the beta parameters from a confusion matrix.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        confusion : array, shape = [n_classes, n_classes]\n",
    "            Where entry c_{ij} is the number of observations in class i but\n",
    "            are classified as class j.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        parameters: array of tuples\n",
    "            Each tuple (alpha_i, beta_i) is the parameters of a Beta distribution\n",
    "            that corresponds to class i.\n",
    "    \"\"\"\n",
    "\n",
    "    alphas, betas = [], []\n",
    "\n",
    "    # number of classes\n",
    "    k = len(confusion)\n",
    "\n",
    "    for i in range(k):\n",
    "        # alpha is 1 plus the number of objects that are correctly classified\n",
    "        alphas.append(1 + confusion[i, i])\n",
    "\n",
    "        # beta is 1 plus the number of objects that are incorrectly classified\n",
    "        betas.append(1 + confusion.sum(axis=1)[i] - confusion[i, i])\n",
    "\n",
    "    return list(zip(alphas, betas))\n",
    "\n",
    "\n",
    "def convolve_betas_fft(parameters, res=0.001):\n",
    "    \"\"\"\n",
    "    Convolve a list of 1d float arrays together, using FFTs.\n",
    "    The arrays need not have the same length, but each array should\n",
    "    have length at least 1.\n",
    "\n",
    "    \"\"\"\n",
    "    # number of convolution\n",
    "    k = len(parameters)\n",
    "\n",
    "    # sum of three probabilities ranges from 0 to k\n",
    "    x = np.arange(0, k+res, res)\n",
    "\n",
    "    # compute the individual beta pdfs\n",
    "    pdfs = []\n",
    "    for par in parameters:\n",
    "        pdfs.append(beta.pdf(x, par[0], par[1]))\n",
    "\n",
    "    result_length = len(pdfs[0])\n",
    "\n",
    "    # Copy each array into a 2d array of the appropriate shape.\n",
    "    rows = numpy.zeros((len(pdfs), result_length))\n",
    "    for i, pdf in enumerate(pdfs):\n",
    "        rows[i] = pdf\n",
    "\n",
    "    # Transform, take the product, and do the inverse transform\n",
    "    # to get the convolution.\n",
    "    fft_of_rows = numpy.fft.fft(rows)\n",
    "    fft_of_convolution = fft_of_rows.prod(axis=0)\n",
    "    convolution = numpy.fft.ifft(fft_of_convolution)\n",
    "\n",
    "    # Assuming real inputs, the imaginary part of the output can\n",
    "    # be ignored.\n",
    "    return convolution.real / (sum(convolution.real) * res)\n",
    "\n",
    "\n",
    "def convolve_betas(parameters, res=0.001):\n",
    "    \"\"\" Convolves k Beta distributions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        parameters : array of tuples\n",
    "            Each tuple (alpha_i, beta_i) is the parameters of a Beta distribution.\n",
    "\n",
    "        res : float, optional (default=0.001)\n",
    "            The precision of the resulting convolution, measured as step size in\n",
    "            the support.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        convolution : array, shape = [k / res]\n",
    "            The resulting convultion of the k Beta distributions, given the\n",
    "            specified presicion `res`.\n",
    "    \"\"\"\n",
    "\n",
    "    # number of convolution\n",
    "    k = len(parameters)\n",
    "\n",
    "    # sum of three probabilities ranges from 0 to k\n",
    "    x = np.arange(0, k+res, res)\n",
    "\n",
    "    # compute the individual beta pdfs\n",
    "    pdfs = []\n",
    "    for par in parameters:\n",
    "        pdfs.append(beta.pdf(x, par[0], par[1]))\n",
    "\n",
    "    # convolve k times\n",
    "    convolution = pdfs[0]\n",
    "    for i in range(1, k):\n",
    "        convolution = np.convolve(convolution, pdfs[i])\n",
    "\n",
    "    # reduce to the [0, k] support\n",
    "    convolution = convolution[0:len(x)]\n",
    "\n",
    "    # normalise so that all values sum to (1 / res)\n",
    "    convolution = convolution / (sum(convolution) * res)\n",
    "\n",
    "    return convolution\n",
    "\n",
    "\n",
    "def balanced_accuracy_expected(confusion, fft=False):\n",
    "    \"\"\" Compute the expected value of the posterior balanced accuracy.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        confusion : array, shape = [n_classes, n_classes]\n",
    "            Where entry c_{ij} is the number of observations in class i but\n",
    "            are classified as class j.\n",
    "        fft: bool\n",
    "            Use efficient fft convolution\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        bal_accuracy_expected: float\n",
    "    \"\"\"\n",
    "\n",
    "    # number of classes\n",
    "    k = len(confusion)\n",
    "\n",
    "    # extract beta distribution parameters from the confusion matrix\n",
    "    parameters = get_beta_parameters(confusion)\n",
    "\n",
    "    # convolve the distributions and compute the expected value\n",
    "    k = len(confusion)\n",
    "    res = 0.001\n",
    "    x = np.arange(0, k + res, res)\n",
    "\n",
    "    if fft:\n",
    "        bal_accuracy = convolve_betas_fft(parameters, res)\n",
    "    else:\n",
    "        bal_accuracy = convolve_betas(parameters, res)\n",
    "    bal_accuracy_expected = (1/k) * np.dot(x, bal_accuracy * res)\n",
    "\n",
    "    return bal_accuracy_expected\n",
    "\n",
    "\n",
    "def beta_sum_pdf(x, parameters, res=0.001, fft=False):\n",
    "    \"\"\" Compute the pdf of the sum of beta distributions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : array\n",
    "            A subset of the domain where we want evaluate the pdf.\n",
    "\n",
    "        parameters : array of tuples\n",
    "            Each tuple (alpha_i, beta_i) is the parameters of a Beta distribution.\n",
    "\n",
    "        res : float, optional (default=0.001)\n",
    "            The precision of the convolution, measured as step size in\n",
    "            the support.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y : array\n",
    "            The pdf evaulated at x.\n",
    "    \"\"\"\n",
    "\n",
    "    if fft:\n",
    "        convolution = convolve_betas_fft(parameters, res)\n",
    "    else:\n",
    "        convolution = convolve_betas(parameters, res)\n",
    "\n",
    "    # convert x into a numpy array if it's not already\n",
    "    x = np.array(x)\n",
    "\n",
    "    # initialise the y vector\n",
    "    y = np.array([np.nan] * len(x))\n",
    "\n",
    "    # upper bound of support\n",
    "    k = len(parameters)\n",
    "\n",
    "    # set y to 0 if we're outside support\n",
    "    y[(x < 0) | (x > k)] = 0\n",
    "\n",
    "    # index in convolution vector that is closest to x\n",
    "    c_index = np.int_(x / res)\n",
    "\n",
    "    # fill in y vector\n",
    "    y[np.isnan(y)] = convolution[c_index[np.isnan(y)]]\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "def beta_avg_pdf(x, parameters, res=0.001, fft=False):\n",
    "    \"\"\" Compute the pdf of the average of the k beta distributions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : array\n",
    "            A subset of the domain where we want evaluate the pdf.\n",
    "\n",
    "        parameters : array of tuples\n",
    "            Each tuple (alpha_i, beta_i) is the parameters of a Beta distribution.\n",
    "\n",
    "        res : float, optional (default=0.001)\n",
    "            The precision of the convolution, measured as step size in\n",
    "            the support.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y : array\n",
    "            The pdf evaulated at x.\n",
    "    \"\"\"\n",
    "\n",
    "    k = len(parameters)\n",
    "    y = beta_sum_pdf(k * np.array(x), parameters, res, fft)\n",
    "    y = y * k\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "def beta_sum_cdf(x, parameters, res=0.001):\n",
    "    \"\"\" Compute the cdf of the sum of the k beta distributions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : array\n",
    "            A subset of the domain where we want evaluate the cdf.\n",
    "\n",
    "        parameters : array of tuples\n",
    "            Each tuple (alpha_i, beta_i) is the parameters of a Beta distribution.\n",
    "\n",
    "        res : float, optional (default=0.001)\n",
    "            The precision of the convolution, measured as step size in\n",
    "            the support.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y : array\n",
    "            The cdf evaulated at x.\n",
    "    \"\"\"\n",
    "\n",
    "    convolution = convolve_betas(parameters, res)\n",
    "\n",
    "    y = np.array([np.nan] * len(x))\n",
    "    for i in range(len(x)):\n",
    "        c_index = int(round(x[i] / res))\n",
    "        if c_index <= 0:\n",
    "            y[i] = 0\n",
    "        elif c_index >= len(convolution):\n",
    "            y[i] = 1\n",
    "        else:\n",
    "            y[i] = trapz(convolution[:c_index+1], dx=res)\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "def beta_avg_cdf(x, parameters, res=0.001):\n",
    "    \"\"\" Compute the cdf of the average of the k beta distributions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : array\n",
    "            A subset of the domain where we want evaluate the cdf.\n",
    "\n",
    "        parameters : array of tuples\n",
    "            Each tuple (alpha_i, beta_i) is the parameters of a Beta distribution.\n",
    "\n",
    "        res : float, optional (default=0.001)\n",
    "            The precision of the convolution, measured as step size in\n",
    "            the support.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y : array\n",
    "            The cdf evaulated at x.\n",
    "    \"\"\"\n",
    "\n",
    "    x = np.array(x)\n",
    "    k = len(parameters)\n",
    "    y = beta_sum_cdf(k * x, parameters, res)\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "def beta_avg_inv_cdf(y, parameters, res=0.001):\n",
    "    \"\"\" Compute the inverse cdf of the average of the k beta distributions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : float\n",
    "            A float between 0 and 1 (the range of the cdf)\n",
    "\n",
    "        parameters : array of tuples\n",
    "            Each tuple (alpha_i, beta_i) is the parameters of a Beta distribution.\n",
    "\n",
    "        res : float, optional (default=0.001)\n",
    "            The precision of the convolution, measured as step size in\n",
    "            the support.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        x : float\n",
    "            the inverse cdf of y\n",
    "    \"\"\"\n",
    "\n",
    "    return brentq(lambda x: beta_avg_cdf([x], parameters, res)[0] - y, 0, 1)\n",
    "\n",
    "\n",
    "def recall(confusion):\n",
    "    \"\"\" Compute the recall from a confusion matrix.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        confusion : array, shape = [n_classes, n_classes]\n",
    "            Where entry c_{ij} is the number of observations in class i but\n",
    "            are classified as class j.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        recalls : array\n",
    "            A list of recalls, one for each class.\n",
    "    \"\"\"\n",
    "\n",
    "    # number of classes\n",
    "    k = len(confusion)\n",
    "\n",
    "    # extract recall from confusion matrix\n",
    "    recalls = []\n",
    "    for i in range(k):\n",
    "        recalls.append(confusion[i, i] / confusion.sum(axis=1)[i])\n",
    "\n",
    "    return recalls\n",
    "\n",
    "\n",
    "def precision(confusion, classes, classifiers):\n",
    "    \"\"\" Compute the precision from a confusion matrix.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        confusion : array, shape = [n_classes, n_classes]\n",
    "            Where entry c_{ij} is the number of observations in class i but\n",
    "            are classified as class j.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        precisions : array\n",
    "            A list of precisions, one for each class.\n",
    "    \"\"\"\n",
    "\n",
    "    # number of classes\n",
    "    k = len(confusion)\n",
    "\n",
    "    # extract recall from confusion matrix\n",
    "    precisions = []\n",
    "    for i in range(k):\n",
    "        precisions.append(confusion[i, i] / confusion.sum(axis=0)[i])\n",
    "\n",
    "    return precisions\n",
    "\n",
    "\n",
    "def mpba_score(y_true, y_pred):\n",
    "    \"\"\" Compute the MPBA score of a classifier based on some test set.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_true : array\n",
    "            Ground truth (correct) labels.\n",
    "\n",
    "        y_pred : array\n",
    "            Predicted labels, as returned by a classifier.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        balanced_accuracy_expected : float\n",
    "            The expected balanced accuracy rate on the test set.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    confusion_test = metrics.confusion_matrix(y_true, y_pred)\n",
    "    return balanced_accuracy_expected(confusion_test)\n",
    "\n",
    "\n",
    "def micro_f1_score(y_true, y_pred, n_classes=None):\n",
    "    \"\"\" Compute the Micro-F1 score of a classifier based on some test set.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_true : array\n",
    "            Ground truth (correct) labels.\n",
    "\n",
    "        y_pred : array\n",
    "            Predicted labels, as returned by a classifier.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        f1_score : float\n",
    "            The F1 score on the test set.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if n_classes is not None:\n",
    "        average = 'binary' if n_classes == 2 else 'micro'\n",
    "    else:\n",
    "        average = 'binary' if len(np.unique(y_true)) == 2 else 'micro'\n",
    "\n",
    "\n",
    "    return metrics.f1_score(y_true, y_pred, average=average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
