{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "from reliability import utils\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import scipy.integrate\n",
    "\n",
    "import mclearn.performance\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def ece(y_probs, y_preds, y_true, balanced=False):\n",
    "    \"\"\"Compute the expected calibration error (ECE).\n",
    "\n",
    "    Parameters:\n",
    "    y_probs (np.array): predicted class probabilities\n",
    "    y_preds (np.array): predicted class labels\n",
    "    y_true (np.array): true class labels\n",
    "\n",
    "    Returns:\n",
    "    exp_ce (float): expected calibration error\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # define the bin function\n",
    "    def bin_func(y_probs_bin, y_preds_bin, y_true_bin):\n",
    "        acc = (y_preds_bin == y_true_bin).mean()\n",
    "        conf = y_probs_bin.mean()\n",
    "        return abs(acc - conf)\n",
    "\n",
    "    # define the balanced bin function\n",
    "    def balanced_bin_func(y_probs_bin, y_preds_bin, y_true_bin):\n",
    "        balacc = sklearn.metrics.balanced_accuracy_score(y_true_bin, y_preds_bin)\n",
    "        conf = y_probs_bin.mean()\n",
    "        return abs(balacc - conf)\n",
    "\n",
    "    # compute the full result\n",
    "    bin_indices = utils.get_bin_indices(y_probs)\n",
    "    func = balanced_bin_func if balanced else bin_func\n",
    "    return utils.binning(y_probs, y_preds, y_true, bin_indices, func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def ece_v2(y_probs, y_preds, y_true):\n",
    "    \"\"\"Compute the expected calibration error based on the expected posterior balanced accuracy (ECEv2).\n",
    "\n",
    "    Parameters:\n",
    "    y_probs (np.array): predicted class probabilities\n",
    "    y_preds (np.array): predicted class labels\n",
    "    y_true (np.array): true class labels\n",
    "\n",
    "    Returns:\n",
    "    exp_ce (float): expected calibration error\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # define the bin function\n",
    "    def bin_func(y_probs_bin, y_preds_bin, y_true_bin):\n",
    "        confusion = sklearn.metrics.confusion_matrix(y_true_bin, y_preds_bin)\n",
    "        acc = mclearn.performance.balanced_accuracy_expected(confusion, fft=True)\n",
    "        conf = y_probs_bin.mean()\n",
    "        return abs(acc - conf)\n",
    "\n",
    "    # compute the full result\n",
    "    bin_indices = utils.get_bin_indices(y_probs)\n",
    "    return utils.binning(y_probs, y_preds, y_true, bin_indices, bin_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def ece_v3(y_probs, y_preds, y_true, samples=1000):\n",
    "    \"\"\"Compute the ECE based on the posterior balanced accuracy distribution (ECEv3).\n",
    "\n",
    "    Parameters:\n",
    "    y_probs (np.array): predicted class probabilities\n",
    "    y_preds (np.array): predicted class labels\n",
    "    y_true (np.array): true class labels\n",
    "    samples (int): number of samples for numerical integration\n",
    "\n",
    "    Returns:\n",
    "    exp_ce (float): expected calibration error\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # define the bin function\n",
    "    def bin_func(y_probs_bin, y_preds_bin, y_true_bin):\n",
    "        # estimate beta parameters\n",
    "        confusion = sklearn.metrics.confusion_matrix(y_true_bin, y_preds_bin)\n",
    "        params = mclearn.performance.get_beta_parameters(confusion)\n",
    "\n",
    "        # approximate the integral using Simpson's rule\n",
    "        xs = np.linspace(0, 1, samples)\n",
    "        conf = y_probs_bin.mean()\n",
    "        ys = abs(xs - conf) * mclearn.performance.beta_avg_pdf(xs, params, fft=True)\n",
    "        return scipy.integrate.simps(ys, xs)\n",
    "\n",
    "    # compute the full result\n",
    "    bin_indices = utils.get_bin_indices(y_probs)\n",
    "    return utils.binning(y_probs, y_preds, y_true, bin_indices, bin_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def ece_v4(y_probs, y_preds, y_true, samples=1000):\n",
    "    \"\"\"Compute the ECE based on the posterior balanced accuracy distribution (ECEv3).\n",
    "\n",
    "    Parameters:\n",
    "    y_probs (np.array): predicted class probabilities\n",
    "    y_preds (np.array): predicted class labels\n",
    "    y_true (np.array): true class labels\n",
    "    samples (int): number of samples for numerical integration\n",
    "\n",
    "    Returns:\n",
    "    exp_ce (float): expected calibration error\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # define the bin function\n",
    "    def bin_func(y_probs_bin, y_preds_bin, y_true_bin):\n",
    "        # estimate beta parameters\n",
    "        confusion = sklearn.metrics.confusion_matrix(y_true_bin, y_preds_bin)\n",
    "        params = mclearn.performance.get_beta_parameters(confusion)\n",
    "\n",
    "        # approximate the integral using Simpson's rule\n",
    "        xs = np.linspace(0, 1, samples)\n",
    "        conf = y_probs_bin.mean()\n",
    "\n",
    "        integrands = np.empty((len(confusion),), dtype=np.float32)\n",
    "        for i in range(len(confusion)):\n",
    "            ys = abs(xs - conf) * scipy.stats.beta.pdf(xs, params[i][0], params[i][1])\n",
    "            integrands[i] = scipy.integrate.simps(ys, xs)\n",
    "\n",
    "        return integrands.mean()\n",
    "\n",
    "    # compute the full result\n",
    "    bin_indices = utils.get_bin_indices(y_probs)\n",
    "    return utils.binning(y_probs, y_preds, y_true, bin_indices, bin_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def class_wise_ece(y_probs, y_preds, y_true, base_ece, *base_ece_args, **base_ece_kwargs):\n",
    "    \"\"\"Compute classwise-ECE as proposed in \"Beyond temperature scaling: Obtaining well-calibrated\n",
    "    multiclass probabilities with Dirichlet calibration\" (Kull, 2019).\n",
    "\n",
    "    Parameters:\n",
    "    y_probs (np.array): predicted class probabilities\n",
    "    y_preds (np.array): predicted class labels\n",
    "    y_true (np.array): true class labels\n",
    "    base_ece (callable): function that returns ECE for given probabilities, label predictions and true labels\n",
    "    base_ece_[kw]args ([kw]args): [Keyword ]arguments that should be passed to the base_ece callable.\n",
    "\n",
    "    Returns:\n",
    "    exp_ce (float): class-wise expected calibration error\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    classes = np.unique(y_preds)\n",
    "    result = 0.\n",
    "    for j in classes:\n",
    "        sel = y_preds == j\n",
    "        result += base_ece(y_probs[sel], y_preds[sel], y_true[sel], *base_ece_args, **base_ece_kwargs)\n",
    "\n",
    "    return result/len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
